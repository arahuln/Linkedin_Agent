{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from linkedin_jobs_scraper import LinkedinScraper, events, query, filters\n",
    "from resume_matcher.matching import resume_job_desc_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_ollama import OllamaLLM\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## LinkedIn Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_RESULTS = []\n",
    "\n",
    "def on_data(data):\n",
    "    JOB_RESULTS.append({\n",
    "        \"title\": data.title,\n",
    "        \"company\": data.company,\n",
    "        \"location\": data.location,\n",
    "        \"description\": data.description,\n",
    "        \"link\": data.link,\n",
    "        \"date\": data.date\n",
    "    })\n",
    "\n",
    "def on_error(error):\n",
    "    print('[ON_ERROR]', error)\n",
    "\n",
    "def on_end():\n",
    "    print('[END]')\n",
    "\n",
    "def scrape_linkedin_jobs(search_term, location = 'Remote', num_jobs = 10):\n",
    "    global JOB_RESULTS\n",
    "    scraper = LinkedinScraper(\n",
    "        chrome_executable_path=None,\n",
    "        # chrome_driver_path=None,\n",
    "        headless=True,\n",
    "        max_workers=1,\n",
    "        slow_mo=0.5,\n",
    "        page_load_timeout=20,\n",
    "        # browser_user_agent=None,\n",
    "        # proxy=None\n",
    "    )\n",
    "    scraper.on(events.Events.DATA, on_data)\n",
    "    scraper.on(events.Events.ERROR, on_error)\n",
    "    scraper.on(events.Events.END, on_end)\n",
    "\n",
    "    queries = [\n",
    "        query.Query(\n",
    "            query=search_term,\n",
    "            options= query.QueryOptions(\n",
    "                locations = [location],\n",
    "                apply_link = True,\n",
    "                limit = num_jobs,\n",
    "                filters = query.QueryFilters(\n",
    "                    experience=[filters.ExperienceLevelFilters.ENTRY_LEVEL],\n",
    "                    type=[filters.TypeFilters.FULL_TIME]\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    scraper.run(queries)\n",
    "    time.sleep(2)\n",
    "    return JOB_RESULTS.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_QUERY = \"AI Engineer\"    # Edit as desired\n",
    "JOB_LOCATION = \"Remote\"\n",
    "NUM_JOBS = 20\n",
    "\n",
    "scraped_jobs = scrape_linkedin_jobs(JOB_QUERY, location=JOB_LOCATION, num_jobs=NUM_JOBS)\n",
    "\n",
    "print(f\"Scraped {len(scraped_jobs)} jobs.\")\n",
    "print(scraped_jobs)  # Display first 5 jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Resume Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze_resume_vs_jobs(resume_path, job_descriptions):\n",
    "#     matcher = resume_job_desc_match(resume_path, job_descriptions)\n",
    "#     job_scores = []\n",
    "#     for idx, job in enumerate(job_descriptions):\n",
    "#         score, missing = matcher.match(job['description'])\n",
    "#         job_scores.append({\n",
    "#             \"job_index\": idx,\n",
    "#             \"title\": job['title'],\n",
    "#             \"company\": job['company'],\n",
    "#             \"score\": score,\n",
    "#             \"missing_keywords\": missing,\n",
    "#             \"description\": job['description'],\n",
    "#             \"link\": job['link'],\n",
    "#         })\n",
    "#     return job_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume_job_desc_match('Manvith_New_Resume.pdf', \"We’re super into the work we do and the community we’ve built and think you might be, too.\\n\\nQ-Centrix is the largest exclusive provider of clinical data management solutions to acute care hospitals. A market disruptor and innovator, Q-Centrix believes that there is nothing more valuable than clinical data as it is critical in delivering safe, consistent, quality healthcare for all. Bringing together deep expertise across providers, clinical knowledge, data and software, Q-Centrix provides an integrated approach that can redefine and streamline the data management and real-world application process for the healthcare industry, thereby enabling increased efficiency and exciting new solution opportunities.\\n\\nProviding the industry’s first Enterprise Clinical Data Management (eCDM™) platform, Q-Centrix utilizes its market-leading software, the largest and broadest team of clinical data experts, a modern-stack software and reporting data structure, and best practices from its 1,200+ hospital partners to securely extract, curate, structure, and enhance clinical data at the highest quality level. The resulting high quality structured clinical data is then utilized to support reporting demands, drive improved care delivery, meet financial and operational needs, enable population health workflows and power broad research use cases. Its solutions cover a breadth of clinical segments, including cardiovascular, oncology, infection prevention, trauma and real-world data applications. Q-Centrix’s platform enables its partners to access valuable clinical information that may otherwise be trapped across multiple workflow systems and clinical information platforms. Q-Centrix is positioned for continued growth as they integrate new capabilities and business lines.\\n\\nJob Summary\\n\\nThis role focuses on deploying AI-powered solutions to extract structured data from unstructured medical charts. The AI Engineer will work with technical and clinical teams to bring AI models into real-world use, improving efficiency in healthcare data processing while ensuring accuracy, usability and responsible AI practices.\\n\\nEssential Functions\\n\\n\\nDevelop, test, and deploy LLM-powered extraction pipelines for clinical text at scale.\\nAutomate prompt execution, result validation, and error handling to enhance reliability.\\nMonitor and maintain production AI models, ensuring uptime, accuracy, and compliance.\\nWork with product, data, engineering, and clinical teams to integrate AI outputs into real-world solutions.\\nEvaluate and integrate third-party AI solutions when appropriate.\\nStay current with advancements in LLM deployment, model serving, and responsible AI practices.\\n\\n\\nRequired Skills/Abilities\\n\\n\\n1+ years of experience in LLM evaluation\\nStrong software engineering foundation with proficiency in Python.\\nFamiliarity with cloud platforms, data engineering and pipeline automation.\\nBachelor’s degree in Computer Science, AI, a related field, or equivalent work experience.\\nStrong cross-functional collaboration skills.\\nProven track record of thriving in a start-up environment.\\n\\n\\nPreferred Education And Experience\\n\\n\\n2+ years of experience in AI deployment or applied Machine Learning.\\nAdvanced degree in Computer Science or related field.\\nExperience integrating AI with healthcare data (EHRs, clinical databases).\\nExperience working in regulated industries with an understanding of security, compliance, and responsible AI.\\n\\n\\nSupervisory Responsibilities: None\\n\\nWork environment/Physical Demands: Continuous sitting and fine manipulation.\\n\\nTravel Requirements: None\\n\\nWork Authorization: Legally able to work in the United States without sponsorship\\n\\nTotal Rewards\\n\\nAt Q-Centrix, our purpose—safer, consistent, quality healthcare for all—drives everything we do. To accomplish this important work, we aim to attract, engage, and retain a talented team by offering a compelling, equitable rewards package. This includes an inclusive culture, a flexible work environment, learning and development opportunities, and robust benefits that support both health and financial wellness. In addition, our supportive community fosters collaboration, learning, growth, and enjoyment, making Q-Centrix a place where meaningful work and a positive work experience go hand in hand. It’s no wonder we’ve earned the Great Place to Work distinction multiple years in a row! The target salary range for this role is $100,000.00 to $120,000.00 per year. An individual’s salary within this range is based on multiple factors including but not limited to skills, experiences, licensure, certifications, and other business and organizational considerations.\\n\\nIn addition to our inclusive and innovative working environment and comprehensive compensation package, team members enjoy:\\n\\n\\nRemote/hybrid flexibility (depending on location) and a generous time off program with additional paid time for volunteering.\\nRobust benefits package including medical, vision, dental, health savings accounts, company paid short- and long-term disability, employee assistance program, paid parental leave, life insurance, accident insurance, and other voluntary benefit programs for employees and their eligible dependents.\\n401(k) retirement plan with a company match.\\nOpportunities for professional development.\\n\\n\\nCommitment To Diversity, Equity, Inclusion And Belonging\\n\\nAt Q-Centrix, we hire people who love learning, value innovation, and believe in our purpose of safer, consistent, quality health care for all. We applaud qualified applicants who are accountable and committed to producing quality work. As an Equal Opportunity Employer, we support and value diversity, dignity, and respect in our work environment, and are committed to creating an inclusive environment in which everyone can thrive.\\n\\nWe employ people based on the needs of the business and the job, and their individual professional qualifications. Here’s what does not impact our employment decisions: race, religious creed, religion, color, sex, sexual orientation, pregnancy, parental status, genetic information, gender, gender identity, gender expression, age, national origin, ancestry, citizenship, protected veteran or disability status, health, marital, civil union or domestic partnership status, or any status or characteristic protected by the laws or regulations in locations where we operate. If you are an individual with a qualified disability and you need an accommodation during the interview process, please reach out to your recruiter.\\n\\nCandidate Privacy Statements\\nShow more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def resume_job_desc_match_2(resume,job_desc):\n",
    "    # job_desc = docx2txt.process(job_desc)\n",
    "    # resume = docx2txt.process(resume)\n",
    "    content = [resume,job_desc]\n",
    "    cv = CountVectorizer()\n",
    "    matrix = cv.fit_transform(content)\n",
    "    similarity_matrix = cosine_similarity(matrix)\n",
    "    match_percentage = similarity_matrix[0][1]*100\n",
    "    return f\"{round(match_percentage, 2)}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Usage\n",
    "pdf_text = extract_text_from_pdf(\"C:/Users/10839330/OneDrive - LTIMindtree/Desktop/Ollama_Agents/Manvith_New_Resume.pdf\")\n",
    "print(pdf_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_job_desc_match_2(pdf_text, scraped_jobs[0]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_jobs = []\n",
    "for i, job in enumerate(scraped_jobs):\n",
    "    print(f\"Job {i+1}: {job['title']} at {job['company']}\")\n",
    "    print(f\"Location: {job['location']}\")\n",
    "    print(f\"Description: {job['description'][:100]}...\")  # Print first 100 characters\n",
    "    print(f\"Link: {job['link']}\")\n",
    "    print(f\"Date Posted: {job['date']}\\n\")\n",
    "    scored_jobs.append({\n",
    "        \"job_index\": i,\n",
    "        \"title\": job['title'],\n",
    "        \"company\": job['company'],\n",
    "        \"score\": resume_job_desc_match_2(pdf_text, job['description']),\n",
    "        \"description\": job['description'],\n",
    "        \"link\": job['link'],\n",
    "    })\n",
    "    print(resume_job_desc_match_2(pdf_text, scraped_jobs[i]['description']))\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Building Resume Enhancing agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ollama_suggestions(resume_text, job_description):\n",
    "    prompt = (\n",
    "        \"You are a career coach and resume expert. Given the following resume and job description, \"\n",
    "        \"suggest specific improvements to the resume to fit this particular job's requirements. \"\n",
    "        \"Resume:\\n%s\\n\\nJob Description:\\n%s\\n\\n\"\n",
    "        \"Return bullet points with concrete suggestions only, and add the missing keywords required.\"\n",
    "    ) % (resume_text, job_description)\n",
    "    # llm = OllamaLLM(\n",
    "    #     model = model,\n",
    "    #     temperature=0.2,\n",
    "    # )\n",
    "    llm = ChatNVIDIA(\n",
    "        model = os.getenv(\"NVIDIA_MODEL_NAME\"),\n",
    "        api_key = os.getenv(\"NVIDIA_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_jobs = sorted(scored_jobs, key= lambda x: x['score'], reverse= True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scored_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []\n",
    "\n",
    "for job in scored_jobs:\n",
    "    suggestions = get_ollama_suggestions(resume_text= pdf_text, job_description= job['description'])\n",
    "    final_results.append({\n",
    "            'title': job['title'],\n",
    "            'company': job['company'],\n",
    "            'score': job['score'],\n",
    "            'link': job['link'],\n",
    "            'suggestions': suggestions\n",
    "        })\n",
    "\n",
    "print(\"\\n--- Top Matching Jobs and Personalized Suggestions ---\\n\")\n",
    "for job in final_results:\n",
    "    print(f\"[{job['title']} at {job['company']}] (Score: {job['score']}%)\")\n",
    "    print(f\"Link: {job['link']}\")\n",
    "    print(\"Improvement Suggestions:\\n\", job['suggestions'])\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
